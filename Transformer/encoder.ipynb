{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "233476a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1144, 0.0046, 0.0214,  ..., 0.4563, 0.4902, 0.6133],\n",
      "         [0.4948, 0.5373, 0.9469,  ..., 0.9110, 0.0448, 0.2678],\n",
      "         [0.3907, 0.7566, 0.0166,  ..., 0.7804, 0.4545, 0.4332],\n",
      "         ...,\n",
      "         [0.3627, 0.8344, 0.7553,  ..., 0.2809, 0.8938, 0.5120],\n",
      "         [0.7503, 0.2429, 0.3945,  ..., 0.9732, 0.4237, 0.3245],\n",
      "         [0.0271, 0.4561, 0.4459,  ..., 0.9863, 0.8973, 0.7299]],\n",
      "\n",
      "        [[0.5833, 0.1978, 0.7175,  ..., 0.6587, 0.0914, 0.2537],\n",
      "         [0.4352, 0.5459, 0.1426,  ..., 0.5748, 0.3792, 0.6530],\n",
      "         [0.7300, 0.0505, 0.2394,  ..., 0.8085, 0.8920, 0.5590],\n",
      "         ...,\n",
      "         [0.2685, 0.5248, 0.3535,  ..., 0.2652, 0.2466, 0.7448],\n",
      "         [0.9634, 0.7131, 0.5718,  ..., 0.3225, 0.3697, 0.7357],\n",
      "         [0.2707, 0.4306, 0.6916,  ..., 0.4921, 0.0199, 0.9593]],\n",
      "\n",
      "        [[0.5002, 0.8096, 0.3362,  ..., 0.3546, 0.2691, 0.0581],\n",
      "         [0.8628, 0.5858, 0.1888,  ..., 0.4056, 0.5291, 0.3356],\n",
      "         [0.9470, 0.9440, 0.2378,  ..., 0.0709, 0.2652, 0.8068],\n",
      "         ...,\n",
      "         [0.6553, 0.9071, 0.2828,  ..., 0.7645, 0.5523, 0.9210],\n",
      "         [0.9765, 0.7116, 0.6118,  ..., 0.8342, 0.9705, 0.2338],\n",
      "         [0.7054, 0.2248, 0.7345,  ..., 0.9484, 0.4508, 0.3033]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9782, 0.2554, 0.2743,  ..., 0.6381, 0.6454, 0.0464],\n",
      "         [0.7170, 0.1995, 0.8533,  ..., 0.9850, 0.0247, 0.8775],\n",
      "         [0.4317, 0.9650, 0.7117,  ..., 0.8324, 0.7871, 0.4946],\n",
      "         ...,\n",
      "         [0.7371, 0.5391, 0.0244,  ..., 0.5543, 0.8750, 0.3589],\n",
      "         [0.6408, 0.8150, 0.2751,  ..., 0.1109, 0.6066, 0.4213],\n",
      "         [0.6011, 0.6074, 0.8623,  ..., 0.9847, 0.3243, 0.0197]],\n",
      "\n",
      "        [[0.4717, 0.3739, 0.2947,  ..., 0.3667, 0.0767, 0.2471],\n",
      "         [0.4123, 0.9253, 0.2039,  ..., 0.1940, 0.6793, 0.7295],\n",
      "         [0.5876, 0.5658, 0.9087,  ..., 0.1446, 0.3774, 0.9219],\n",
      "         ...,\n",
      "         [0.6938, 0.1523, 0.3902,  ..., 0.6542, 0.0290, 0.3732],\n",
      "         [0.6497, 0.1791, 0.3972,  ..., 0.0887, 0.2940, 0.6816],\n",
      "         [0.4458, 0.7557, 0.9542,  ..., 0.2616, 0.9278, 0.4115]],\n",
      "\n",
      "        [[0.6684, 0.9597, 0.4847,  ..., 0.7843, 0.3415, 0.7032],\n",
      "         [0.4965, 0.0638, 0.6301,  ..., 0.8587, 0.4700, 0.4442],\n",
      "         [0.6161, 0.3224, 0.4266,  ..., 0.9743, 0.2158, 0.5384],\n",
      "         ...,\n",
      "         [0.2414, 0.5428, 0.1887,  ..., 0.2652, 0.0596, 0.5975],\n",
      "         [0.2471, 0.7635, 0.7570,  ..., 0.2785, 0.6503, 0.6781],\n",
      "         [0.5003, 0.5139, 0.4761,  ..., 0.0885, 0.8387, 0.3384]]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[128, 32, 8, 64]' is invalid for input of size 32768",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_26393/4012278150.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out\u001b[38;5;241m=\u001b[39m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(out)\n",
      "File \u001b[0;32m~/anaconda3/envs/transformer/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/transformer/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/tmp/ipykernel_26393/2764923552.py:27\u001b[0m, in \u001b[0;36mMutiHeadAttention.forward\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     26\u001b[0m q,k,v\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_q(q),\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_k(k),\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_v(v)   \u001b[38;5;66;03m#q,k,v线性映射成Q,K,V\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m q\u001b[38;5;241m=\u001b[39m\u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_head\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_d\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#view从后往前看，把tensor先变成(sum,)，然后从最后一个维度开始分块，依次往前\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#permute就是维度互换    从左往后对齐序列\u001b[39;00m\n\u001b[1;32m     30\u001b[0m k\u001b[38;5;241m=\u001b[39mk\u001b[38;5;241m.\u001b[39mview(batch,time,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_head,n_d)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[128, 32, 8, 64]' is invalid for input of size 32768"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[128, 32, 8, 64]' is invalid for input of size 32768",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention.ipynb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/transformer/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2482\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2480\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2482\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2486\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/transformer/lib/python3.10/site-packages/IPython/core/magics/execution.py:741\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m preserve_keys(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39muser_ns, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    740\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m--> 741\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_execfile_ipy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;66;03m# Control the response to exit() calls made by the script being run\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/transformer/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3007\u001b[0m, in \u001b[0;36mInteractiveShell.safe_execfile_ipy\u001b[0;34m(self, fname, shell_futures, raise_exceptions)\u001b[0m\n\u001b[1;32m   3005\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_cell(cell, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, shell_futures\u001b[38;5;241m=\u001b[39mshell_futures)\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_exceptions:\n\u001b[0;32m-> 3007\u001b[0m     \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3008\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39msuccess:\n\u001b[1;32m   3009\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/transformer/lib/python3.10/site-packages/IPython/core/interactiveshell.py:308\u001b[0m, in \u001b[0;36mExecutionResult.raise_error\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_before_exec\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_in_exec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_in_exec\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/tmp/ipykernel_26393/4012278150.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out\u001b[38;5;241m=\u001b[39m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(out)\n",
      "File \u001b[0;32m~/anaconda3/envs/transformer/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/transformer/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/tmp/ipykernel_26393/2764923552.py:27\u001b[0m, in \u001b[0;36mMutiHeadAttention.forward\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     26\u001b[0m q,k,v\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_q(q),\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_k(k),\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_v(v)   \u001b[38;5;66;03m#q,k,v线性映射成Q,K,V\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m q\u001b[38;5;241m=\u001b[39m\u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_head\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_d\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#view从后往前看，把tensor先变成(sum,)，然后从最后一个维度开始分块，依次往前\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#permute就是维度互换    从左往后对齐序列\u001b[39;00m\n\u001b[1;32m     30\u001b[0m k\u001b[38;5;241m=\u001b[39mk\u001b[38;5;241m.\u001b[39mview(batch,time,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_head,n_d)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[128, 32, 8, 64]' is invalid for input of size 32768"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "%run attention.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab987a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self,d_model,hidden,dropout=0.1):\n",
    "        super(PositionwiseFeedForward,self).__init__()\n",
    "        self.fc1=nn.Linear(d_model,hidden)\n",
    "        self.fc2=nn.Linear(hidden,d_model)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.fc1(x)\n",
    "        x=F.relu(x)\n",
    "        x=self.dropout(x)\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "#就是Feed Forward模块的内部构造"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c616c55",
   "metadata": {},
   "source": [
    "![](structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da75ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (983408655.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __init__(self,d_model,ffn_hidden,n_head,dropout=0.1)\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,d_model,ffn_hidden,n_head,dropout=0.1):\n",
    "        super(EncoderLayer,self).__init__()\n",
    "        self.attention=MultiHeadAttention(d_model,n_head)\n",
    "        #注意力层\n",
    "        self.norm1=LayerNorm(d_model)\n",
    "        self.dropout1=nn.Dropout(dropout)\n",
    "        self.ffn=PostionwiseFeedForward(d_model,ffn_hidden,dropout)\n",
    "        self.norm2=LayerNorm(d_model)\n",
    "        self.dropout2=nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x,mask=None):\n",
    "        _x=x\n",
    "        #残差\n",
    "        x=self.attention(x,x,x,mask)\n",
    "        x=self.dropout1(x)\n",
    "        x=self.norm1(x+_x)\n",
    "        _x=x\n",
    "        x=self.ffn(x)\n",
    "        x=self.dropout2(x)\n",
    "        x=self.norm2(x+_x)\n",
    "        return x\n",
    "#EncoderLayer完全按paper(见上图)来构造的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45a80ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (3387938648.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __init__(self,enc_voc_size,max_len,d_model,ffn_hidden,n_head,n_layer,dropout=0.1,device):\u001b[0m\n\u001b[0m                                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,enc_voc_size,max_len,d_model,ffn_hidden,n_head,n_layer,dropout=0.1,device):\n",
    "        #enc_voc_size词汇表大小 \n",
    "        super(Encoder,self).__init__()\n",
    "        self.embedding=TransformerEmbedding(enc_voc_size,max_len,d_model,dropout=0.1,device)\n",
    "        self.layers=nn.ModuleList(\n",
    "            [\n",
    "                EncoderLayer(d_model,ffn_hidden,n_head,device)\n",
    "                for _ in range(n_layer)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self,x,s_mask):\n",
    "        x=self.embedding(x)\n",
    "        for layer in self.layers:\n",
    "            x=layer(x,s_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559b3b72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
